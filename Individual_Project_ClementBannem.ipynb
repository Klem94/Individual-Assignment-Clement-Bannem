{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "First_name = \"Clement\"\n",
    "Last_Name = \"Bannem\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'ROCR' was built under R version 3.6.2\"Loading required package: gplots\n",
      "Warning message:\n",
      "\"package 'gplots' was built under R version 3.6.2\"\n",
      "Attaching package: 'gplots'\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    lowess\n",
      "\n",
      "Warning message:\n",
      "\"package 'Boruta' was built under R version 3.6.3\"Loading required package: ranger\n",
      "Warning message:\n",
      "\"package 'ranger' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'stringr' was built under R version 3.6.1\"Warning message:\n",
      "\"package 'mlr' was built under R version 3.6.2\"Loading required package: ParamHelpers\n",
      "Warning message:\n",
      "\"package 'ParamHelpers' was built under R version 3.6.2\"'mlr' is in maintenance mode since July 2019. Future development\n",
      "efforts will go into its successor 'mlr3' (<https://mlr3.mlr-org.com>).\n",
      "\n",
      "Attaching package: 'mlr'\n",
      "\n",
      "The following object is masked from 'package:ROCR':\n",
      "\n",
      "    performance\n",
      "\n",
      "Warning message:\n",
      "\"package 'caret' was built under R version 3.6.2\"Loading required package: lattice\n",
      "Loading required package: ggplot2\n",
      "Warning message:\n",
      "\"package 'ggplot2' was built under R version 3.6.1\"\n",
      "Attaching package: 'caret'\n",
      "\n",
      "The following object is masked from 'package:mlr':\n",
      "\n",
      "    train\n",
      "\n",
      "Warning message:\n",
      "\"package 'randomForest' was built under R version 3.6.2\"randomForest 4.6-14\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "Attaching package: 'randomForest'\n",
      "\n",
      "The following object is masked from 'package:ggplot2':\n",
      "\n",
      "    margin\n",
      "\n",
      "The following object is masked from 'package:ranger':\n",
      "\n",
      "    importance\n",
      "\n",
      "Warning message:\n",
      "\"package 'gbm' was built under R version 3.6.2\"Loaded gbm 2.1.5\n",
      "Warning message:\n",
      "\"package 'xgboost' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'tidyverse' was built under R version 3.6.2\"-- Attaching packages --------------------------------------- tidyverse 1.3.0 --\n",
      "v tibble  2.1.3     v purrr   0.3.3\n",
      "v tidyr   1.0.0     v dplyr   0.8.3\n",
      "v readr   1.3.1     v forcats 0.4.0\n",
      "Warning message:\n",
      "\"package 'tibble' was built under R version 3.6.1\"Warning message:\n",
      "\"package 'tidyr' was built under R version 3.6.1\"Warning message:\n",
      "\"package 'readr' was built under R version 3.6.1\"Warning message:\n",
      "\"package 'purrr' was built under R version 3.6.2\"Warning message:\n",
      "\"package 'dplyr' was built under R version 3.6.1\"Warning message:\n",
      "\"package 'forcats' was built under R version 3.6.1\"-- Conflicts ------------------------------------------ tidyverse_conflicts() --\n",
      "x dplyr::combine()       masks randomForest::combine()\n",
      "x dplyr::filter()        masks stats::filter()\n",
      "x dplyr::lag()           masks stats::lag()\n",
      "x purrr::lift()          masks caret::lift()\n",
      "x randomForest::margin() masks ggplot2::margin()\n",
      "x dplyr::select()        masks MASS::select()\n",
      "x dplyr::slice()         masks xgboost::slice()\n",
      "dummies-1.5.6 provided by Decision Patterns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(ROCR)\n",
    "# if(!require(\"Boruta\"))install.packages(\"Boruta\")\n",
    "library(Boruta)\n",
    "library(stringr)          # String, text processing\n",
    "\n",
    "# Machine learning library\n",
    "library(mlr)          # Machine learning framework\n",
    "library(caret)         # Data processing and machine learning framework\n",
    "library(MASS)          # LDA\n",
    "library(randomForest)  # RF\n",
    "library(gbm)           # Boosting Tree\n",
    "library(xgboost)       # XGboost\n",
    "library(caret)\n",
    "\n",
    "library(tidyverse)  #Data manipulation and visualization\n",
    "\n",
    "# install.packages(\"dummies\")\n",
    "library(dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "### DataSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read.csv(file = \"C:/Users/abannem/Documents/MSc In Big Data For Business/Courses/16. Statistical & Machine Learning Approches For Marketing/Individual Project/In-class Kaggle Competition/data/bank_mkt/bank_mkt_train.csv\")\n",
    "test_data = read.csv(file = \"C:/Users/abannem/Documents/MSc In Big Data For Business/Courses/16. Statistical & Machine Learning Approches For Marketing/Individual Project/In-class Kaggle Competition/data/bank_mkt/bank_mkt_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t7000 obs. of  21 variables:\n",
      " $ client_id     : int  2 3 4 5 6 7 8 9 14 15 ...\n",
      " $ age           : int  29 39 49 32 29 51 34 52 52 29 ...\n",
      " $ job           : Factor w/ 12 levels \"admin.\",\"blue-collar\",..: 4 11 2 7 1 7 2 8 1 1 ...\n",
      " $ marital       : Factor w/ 4 levels \"divorced\",\"married\",..: 3 2 2 3 3 2 2 2 2 3 ...\n",
      " $ education     : Factor w/ 8 levels \"basic.4y\",\"basic.6y\",..: 4 3 2 7 4 7 1 4 7 7 ...\n",
      " $ default       : Factor w/ 2 levels \"no\",\"unknown\": 1 2 2 1 2 2 1 1 1 1 ...\n",
      " $ housing       : Factor w/ 3 levels \"no\",\"unknown\",..: 1 3 1 3 3 3 3 3 3 3 ...\n",
      " $ loan          : Factor w/ 3 levels \"no\",\"unknown\",..: 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ contact       : Factor w/ 2 levels \"cellular\",\"telephone\": 2 2 1 1 1 2 1 1 1 1 ...\n",
      " $ month         : Factor w/ 10 levels \"apr\",\"aug\",\"dec\",..: 7 5 8 7 4 5 8 8 8 5 ...\n",
      " $ day_of_week   : Factor w/ 5 levels \"fri\",\"mon\",\"thu\",..: 2 1 4 2 1 4 4 4 3 2 ...\n",
      " $ campaign      : int  3 6 2 3 2 1 1 1 3 1 ...\n",
      " $ pdays         : int  999 999 999 999 999 999 999 999 999 999 ...\n",
      " $ previous      : int  0 0 0 1 0 0 0 0 0 0 ...\n",
      " $ poutcome      : Factor w/ 3 levels \"failure\",\"nonexistent\",..: 2 2 2 1 2 2 2 2 2 2 ...\n",
      " $ emp.var.rate  : num  1.1 1.4 -0.1 -1.8 1.4 1.4 -0.1 -0.1 -0.1 -2.9 ...\n",
      " $ cons.price.idx: num  94 94.5 93.2 92.9 93.9 ...\n",
      " $ cons.conf.idx : num  -36.4 -41.8 -42 -46.2 -42.7 -41.8 -42 -42 -42 -40.8 ...\n",
      " $ euribor3m     : num  4.86 4.96 4.15 1.3 4.96 ...\n",
      " $ nr.employed   : num  5191 5228 5196 5099 5228 ...\n",
      " $ subscribe     : int  0 0 0 0 0 0 0 0 0 0 ...\n"
     ]
    }
   ],
   "source": [
    "# Checking of data type\n",
    "\n",
    "str(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>client_id</th><th scope=col>age</th><th scope=col>job</th><th scope=col>marital</th><th scope=col>education</th><th scope=col>default</th><th scope=col>housing</th><th scope=col>loan</th><th scope=col>contact</th><th scope=col>month</th><th scope=col>...</th><th scope=col>campaign</th><th scope=col>pdays</th><th scope=col>previous</th><th scope=col>poutcome</th><th scope=col>emp.var.rate</th><th scope=col>cons.price.idx</th><th scope=col>cons.conf.idx</th><th scope=col>euribor3m</th><th scope=col>nr.employed</th><th scope=col>subscribe</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>2                </td><td>29               </td><td>housemaid        </td><td>single           </td><td>high.school      </td><td>no               </td><td>no               </td><td>no               </td><td>telephone        </td><td>may              </td><td>...              </td><td>3                </td><td>999              </td><td>0                </td><td>nonexistent      </td><td> 1.1             </td><td>93.994           </td><td>-36.4            </td><td>4.858            </td><td>5191.0           </td><td>0                </td></tr>\n",
       "\t<tr><td>3                </td><td>39               </td><td>unemployed       </td><td>married          </td><td>basic.9y         </td><td>unknown          </td><td>yes              </td><td>no               </td><td>telephone        </td><td>jun              </td><td>...              </td><td>6                </td><td>999              </td><td>0                </td><td>nonexistent      </td><td> 1.4             </td><td>94.465           </td><td>-41.8            </td><td>4.959            </td><td>5228.1           </td><td>0                </td></tr>\n",
       "\t<tr><td>4                </td><td>49               </td><td>blue-collar      </td><td>married          </td><td>basic.6y         </td><td>unknown          </td><td>no               </td><td>no               </td><td>cellular         </td><td>nov              </td><td>...              </td><td>2                </td><td>999              </td><td>0                </td><td>nonexistent      </td><td>-0.1             </td><td>93.200           </td><td>-42.0            </td><td>4.153            </td><td>5195.8           </td><td>0                </td></tr>\n",
       "\t<tr><td>5                </td><td>32               </td><td>self-employed    </td><td>single           </td><td>university.degree</td><td>no               </td><td>yes              </td><td>no               </td><td>cellular         </td><td>may              </td><td>...              </td><td>3                </td><td>999              </td><td>1                </td><td>failure          </td><td>-1.8             </td><td>92.893           </td><td>-46.2            </td><td>1.299            </td><td>5099.1           </td><td>0                </td></tr>\n",
       "\t<tr><td>6                </td><td>29               </td><td>admin.           </td><td>single           </td><td>high.school      </td><td>unknown          </td><td>yes              </td><td>no               </td><td>cellular         </td><td>jul              </td><td>...              </td><td>2                </td><td>999              </td><td>0                </td><td>nonexistent      </td><td> 1.4             </td><td>93.918           </td><td>-42.7            </td><td>4.963            </td><td>5228.1           </td><td>0                </td></tr>\n",
       "\t<tr><td>7                </td><td>51               </td><td>self-employed    </td><td>married          </td><td>university.degree</td><td>unknown          </td><td>yes              </td><td>no               </td><td>telephone        </td><td>jun              </td><td>...              </td><td>1                </td><td>999              </td><td>0                </td><td>nonexistent      </td><td> 1.4             </td><td>94.465           </td><td>-41.8            </td><td>4.864            </td><td>5228.1           </td><td>0                </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       " client\\_id & age & job & marital & education & default & housing & loan & contact & month & ... & campaign & pdays & previous & poutcome & emp.var.rate & cons.price.idx & cons.conf.idx & euribor3m & nr.employed & subscribe\\\\\n",
       "\\hline\n",
       "\t 2                 & 29                & housemaid         & single            & high.school       & no                & no                & no                & telephone         & may               & ...               & 3                 & 999               & 0                 & nonexistent       &  1.1              & 93.994            & -36.4             & 4.858             & 5191.0            & 0                \\\\\n",
       "\t 3                 & 39                & unemployed        & married           & basic.9y          & unknown           & yes               & no                & telephone         & jun               & ...               & 6                 & 999               & 0                 & nonexistent       &  1.4              & 94.465            & -41.8             & 4.959             & 5228.1            & 0                \\\\\n",
       "\t 4                 & 49                & blue-collar       & married           & basic.6y          & unknown           & no                & no                & cellular          & nov               & ...               & 2                 & 999               & 0                 & nonexistent       & -0.1              & 93.200            & -42.0             & 4.153             & 5195.8            & 0                \\\\\n",
       "\t 5                 & 32                & self-employed     & single            & university.degree & no                & yes               & no                & cellular          & may               & ...               & 3                 & 999               & 1                 & failure           & -1.8              & 92.893            & -46.2             & 1.299             & 5099.1            & 0                \\\\\n",
       "\t 6                 & 29                & admin.            & single            & high.school       & unknown           & yes               & no                & cellular          & jul               & ...               & 2                 & 999               & 0                 & nonexistent       &  1.4              & 93.918            & -42.7             & 4.963             & 5228.1            & 0                \\\\\n",
       "\t 7                 & 51                & self-employed     & married           & university.degree & unknown           & yes               & no                & telephone         & jun               & ...               & 1                 & 999               & 0                 & nonexistent       &  1.4              & 94.465            & -41.8             & 4.864             & 5228.1            & 0                \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| client_id | age | job | marital | education | default | housing | loan | contact | month | ... | campaign | pdays | previous | poutcome | emp.var.rate | cons.price.idx | cons.conf.idx | euribor3m | nr.employed | subscribe |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 2                 | 29                | housemaid         | single            | high.school       | no                | no                | no                | telephone         | may               | ...               | 3                 | 999               | 0                 | nonexistent       |  1.1              | 93.994            | -36.4             | 4.858             | 5191.0            | 0                 |\n",
       "| 3                 | 39                | unemployed        | married           | basic.9y          | unknown           | yes               | no                | telephone         | jun               | ...               | 6                 | 999               | 0                 | nonexistent       |  1.4              | 94.465            | -41.8             | 4.959             | 5228.1            | 0                 |\n",
       "| 4                 | 49                | blue-collar       | married           | basic.6y          | unknown           | no                | no                | cellular          | nov               | ...               | 2                 | 999               | 0                 | nonexistent       | -0.1              | 93.200            | -42.0             | 4.153             | 5195.8            | 0                 |\n",
       "| 5                 | 32                | self-employed     | single            | university.degree | no                | yes               | no                | cellular          | may               | ...               | 3                 | 999               | 1                 | failure           | -1.8              | 92.893            | -46.2             | 1.299             | 5099.1            | 0                 |\n",
       "| 6                 | 29                | admin.            | single            | high.school       | unknown           | yes               | no                | cellular          | jul               | ...               | 2                 | 999               | 0                 | nonexistent       |  1.4              | 93.918            | -42.7             | 4.963             | 5228.1            | 0                 |\n",
       "| 7                 | 51                | self-employed     | married           | university.degree | unknown           | yes               | no                | telephone         | jun               | ...               | 1                 | 999               | 0                 | nonexistent       |  1.4              | 94.465            | -41.8             | 4.864             | 5228.1            | 0                 |\n",
       "\n"
      ],
      "text/plain": [
       "  client_id age job           marital education         default housing loan\n",
       "1 2         29  housemaid     single  high.school       no      no      no  \n",
       "2 3         39  unemployed    married basic.9y          unknown yes     no  \n",
       "3 4         49  blue-collar   married basic.6y          unknown no      no  \n",
       "4 5         32  self-employed single  university.degree no      yes     no  \n",
       "5 6         29  admin.        single  high.school       unknown yes     no  \n",
       "6 7         51  self-employed married university.degree unknown yes     no  \n",
       "  contact   month ... campaign pdays previous poutcome    emp.var.rate\n",
       "1 telephone may   ... 3        999   0        nonexistent  1.1        \n",
       "2 telephone jun   ... 6        999   0        nonexistent  1.4        \n",
       "3 cellular  nov   ... 2        999   0        nonexistent -0.1        \n",
       "4 cellular  may   ... 3        999   1        failure     -1.8        \n",
       "5 cellular  jul   ... 2        999   0        nonexistent  1.4        \n",
       "6 telephone jun   ... 1        999   0        nonexistent  1.4        \n",
       "  cons.price.idx cons.conf.idx euribor3m nr.employed subscribe\n",
       "1 93.994         -36.4         4.858     5191.0      0        \n",
       "2 94.465         -41.8         4.959     5228.1      0        \n",
       "3 93.200         -42.0         4.153     5195.8      0        \n",
       "4 92.893         -46.2         1.299     5099.1      0        \n",
       "5 93.918         -42.7         4.963     5228.1      0        \n",
       "6 94.465         -41.8         4.864     5228.1      0        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Splitting into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "smp_size <- floor(0.75 * nrow(train_data))\n",
    "\n",
    "# set the seed to make your partition reproducible\n",
    "set.seed(1)\n",
    "train_ind <- sample(seq_len(nrow(train_data)), size = smp_size)\n",
    "\n",
    "train <- train_data[train_ind, ]\n",
    "test <- train_data[-train_ind, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set.seed(1)\n",
    "\n",
    "# train_idx <- caret::createDataPartition(y=train_data[, 'subscribe'], p=.70, list=F)\n",
    "\n",
    "# train <- train_data[train_idx, ]  # Train 60%\n",
    "# test <- train_data[-train_idx, ]  # Test 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   0    1 \n",
       "4645  605 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "   0    1 \n",
       "1533  217 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the train and test set distribution\n",
    "\n",
    "table(train$subscribe)\n",
    "table(test$subscribe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features ingineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the IV and DV list name\n",
    "# Dependent variable (DV)\n",
    "dv_list <- c('subscribe')\n",
    "# Independent variable (IV)\n",
    "iv_list <- setdiff(colnames(train), dv_list)  # Exclude the target variable\n",
    "iv_list <- setdiff(iv_list, 'client_id')  # Exclude the client_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_bool_list <- c()  # List to store boolean variable\n",
    "iv_cat_list <- c()  # List to store categorical variable\n",
    "\n",
    "for (v in iv_list) {\n",
    "    if (class(train[, v]) == 'logical') {  # Logical == boolean variable\n",
    "        iv_bool_list <- c(iv_bool_list, v)\n",
    "    }\n",
    "    else if (class(train[, v]) == 'factor') {  # Factor == categorical variable\n",
    "        iv_cat_list <- c(iv_cat_list, v)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'job'</li>\n",
       "\t<li>'marital'</li>\n",
       "\t<li>'education'</li>\n",
       "\t<li>'default'</li>\n",
       "\t<li>'housing'</li>\n",
       "\t<li>'loan'</li>\n",
       "\t<li>'contact'</li>\n",
       "\t<li>'month'</li>\n",
       "\t<li>'day_of_week'</li>\n",
       "\t<li>'poutcome'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'job'\n",
       "\\item 'marital'\n",
       "\\item 'education'\n",
       "\\item 'default'\n",
       "\\item 'housing'\n",
       "\\item 'loan'\n",
       "\\item 'contact'\n",
       "\\item 'month'\n",
       "\\item 'day\\_of\\_week'\n",
       "\\item 'poutcome'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'job'\n",
       "2. 'marital'\n",
       "3. 'education'\n",
       "4. 'default'\n",
       "5. 'housing'\n",
       "6. 'loan'\n",
       "7. 'contact'\n",
       "8. 'month'\n",
       "9. 'day_of_week'\n",
       "10. 'poutcome'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"job\"         \"marital\"     \"education\"   \"default\"     \"housing\"    \n",
       " [6] \"loan\"        \"contact\"     \"month\"       \"day_of_week\" \"poutcome\"   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iv_cat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\""
     ]
    }
   ],
   "source": [
    "# Dummytizing of all the categorical variables on the train set\n",
    "\n",
    "train <- dummy.data.frame(train, names = iv_cat_list, sep = \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"education.illiterate\"] = NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\""
     ]
    }
   ],
   "source": [
    "# Dummytizing of all the categorical variables on the test set\n",
    "\n",
    "test <- dummy.data.frame(test, names = iv_cat_list, sep = \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\""
     ]
    }
   ],
   "source": [
    "# Dummytizing of all the categorical variables on the test data set\n",
    "\n",
    "test_data <- dummy.data.frame(test_data, names = iv_cat_list, sep = \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### binning of the variable \"age\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins <- c(-Inf, 40, 60, 80, Inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "values <- c(1, 2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below 40 = 1\n",
    "# from 40 to 60 = 2\n",
    "# from 60 to 80 = 3\n",
    "# above 80 = 4\n",
    "\n",
    "train$age.binned <- as.numeric(cut(train$age, breaks = bins, labels = values))\n",
    "test$age.binned <- as.numeric(cut(test$age, breaks = bins, labels = values))\n",
    "\n",
    "test_data$age.binned <- as.numeric(cut(test_data$age, breaks = bins, labels = values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSet$age.binned <- as.numeric(DataSet$age.binned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new variable to train and test (holdout)\n",
    "# pdays == 999 is a special value\n",
    "# Train, valid, test\n",
    "train[, 'pdays_999'] <- as.logical(train$pdays == 999)\n",
    "test[, 'pdays_999'] <- as.logical(test$pdays == 999)\n",
    "# Test (holdout)\n",
    "test_data[, 'pdays_999'] <- as.logical(test_data$pdays == 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean to int\n",
    "for (v in iv_bool_list) {\n",
    "    # Train, valid, test\n",
    "    train[, v] <- as.integer(train[, v])\n",
    "    test[, v] <- as.integer(test[, v])\n",
    "    \n",
    "    # Test (holdout)\n",
    "    test_data[, v] <- as.integer(test_data[, v])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variable Correcting and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check and correct infinite values on the train and test set\n",
    "\n",
    "sum(apply(sapply(train, is.infinite), 2, sum))\n",
    "sum(apply(sapply(test, is.infinite), 2, sum))\n",
    "\n",
    "sum(apply(sapply(test_data, is.infinite), 2, sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check and correct missing values\n",
    "\n",
    "sum(apply(is.na(train), 2, sum))\n",
    "sum(apply(is.na(test), 2, sum))\n",
    "\n",
    "sum(apply(is.na(test_data), 2, sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection : Boruta method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Boruta search\n",
    "boruta_output <- Boruta(subscribe + client_id~., data=train, doTrace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'finalDecision'</li>\n",
       "\t<li>'ImpHistory'</li>\n",
       "\t<li>'pValue'</li>\n",
       "\t<li>'maxRuns'</li>\n",
       "\t<li>'light'</li>\n",
       "\t<li>'mcAdj'</li>\n",
       "\t<li>'timeTaken'</li>\n",
       "\t<li>'roughfixed'</li>\n",
       "\t<li>'call'</li>\n",
       "\t<li>'impSource'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'finalDecision'\n",
       "\\item 'ImpHistory'\n",
       "\\item 'pValue'\n",
       "\\item 'maxRuns'\n",
       "\\item 'light'\n",
       "\\item 'mcAdj'\n",
       "\\item 'timeTaken'\n",
       "\\item 'roughfixed'\n",
       "\\item 'call'\n",
       "\\item 'impSource'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'finalDecision'\n",
       "2. 'ImpHistory'\n",
       "3. 'pValue'\n",
       "4. 'maxRuns'\n",
       "5. 'light'\n",
       "6. 'mcAdj'\n",
       "7. 'timeTaken'\n",
       "8. 'roughfixed'\n",
       "9. 'call'\n",
       "10. 'impSource'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"finalDecision\" \"ImpHistory\"    \"pValue\"        \"maxRuns\"      \n",
       " [5] \"light\"         \"mcAdj\"         \"timeTaken\"     \"roughfixed\"   \n",
       " [9] \"call\"          \"impSource\"    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(boruta_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get significant variables including tentatives\n",
    "boruta_signif <- getSelectedAttributes(boruta_output, withTentative = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"age\"               \"job.unknown\"       \"contact.cellular\" \n",
      " [4] \"contact.telephone\" \"month.aug\"         \"pdays\"            \n",
      " [7] \"previous\"          \"poutcome.success\"  \"emp.var.rate\"     \n",
      "[10] \"cons.price.idx\"    \"euribor3m\"         \"nr.employed\"      \n",
      "[13] \"age.binned\"       \n"
     ]
    }
   ],
   "source": [
    "print(boruta_signif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boruta_signif <- boruta_signif[c(1:10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(boruta_signif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply variable selection to the data\n",
    "# Train\n",
    "var_select <- names(train)[names(train) %in% boruta_signif]\n",
    "train_processed <- train[, c('client_id', var_select, 'subscribe')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "var_select <- names(test)[names(test) %in% boruta_signif]\n",
    "test_processed <- test[, c('client_id', var_select, 'subscribe')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test (holdout)\n",
    "var_select <- names(test_data)[names(test_data) %in% boruta_signif]\n",
    "test_holdout_processed <- test_data[, c('client_id', var_select)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>5250</li>\n",
       "\t<li>15</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 5250\n",
       "\\item 15\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 5250\n",
       "2. 15\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 5250   15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1750</li>\n",
       "\t<li>15</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1750\n",
       "\\item 15\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1750\n",
       "2. 15\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1750   15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>3000</li>\n",
       "\t<li>14</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 3000\n",
       "\\item 14\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 3000\n",
       "2. 14\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 3000   14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(train_processed)\n",
    "dim(test_processed)\n",
    "dim(test_holdout_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the data columns\n",
    "for (v in colnames(train_processed)) {\n",
    "    \n",
    "    # Fix the column name\n",
    "    fix_name <- str_replace_all(v, \"[^[:alnum:] ]\", \"_\")\n",
    "    fix_name <- gsub(' +', '', fix_name) \n",
    "    \n",
    "    # Train, valid, test\n",
    "    colnames(train_processed)[colnames(train_processed) == v] <- fix_name\n",
    "    colnames(test_processed)[colnames(test_processed) == v] <- fix_name\n",
    "    \n",
    "    # Test (holdout)\n",
    "    colnames(test_holdout_processed)[colnames(test_holdout_processed) == v] <- fix_name\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>client_id</th><th scope=col>age</th><th scope=col>job_unknown</th><th scope=col>contact_cellular</th><th scope=col>contact_telephone</th><th scope=col>month_aug</th><th scope=col>pdays</th><th scope=col>previous</th><th scope=col>poutcome_success</th><th scope=col>emp_var_rate</th><th scope=col>cons_price_idx</th><th scope=col>euribor3m</th><th scope=col>nr_employed</th><th scope=col>age_binned</th><th scope=col>subscribe</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1017</th><td>1472  </td><td>44    </td><td>0     </td><td>1     </td><td>0     </td><td>0     </td><td>999   </td><td>0     </td><td>0     </td><td> 1.4  </td><td>93.918</td><td>4.960 </td><td>5228.1</td><td>2     </td><td>0     </td></tr>\n",
       "\t<tr><th scope=row>4775</th><td>6809  </td><td>35    </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>999   </td><td>0     </td><td>0     </td><td>-1.8  </td><td>92.893</td><td>1.281 </td><td>5099.1</td><td>1     </td><td>0     </td></tr>\n",
       "\t<tr><th scope=row>2177</th><td>3103  </td><td>35    </td><td>1     </td><td>0     </td><td>1     </td><td>0     </td><td>999   </td><td>0     </td><td>0     </td><td> 1.1  </td><td>93.994</td><td>4.855 </td><td>5191.0</td><td>1     </td><td>0     </td></tr>\n",
       "\t<tr><th scope=row>5026</th><td>7194  </td><td>44    </td><td>0     </td><td>1     </td><td>0     </td><td>0     </td><td>999   </td><td>0     </td><td>0     </td><td>-1.8  </td><td>92.893</td><td>1.299 </td><td>5099.1</td><td>2     </td><td>0     </td></tr>\n",
       "\t<tr><th scope=row>1533</th><td>2195  </td><td>32    </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>999   </td><td>0     </td><td>0     </td><td> 1.4  </td><td>93.918</td><td>4.968 </td><td>5228.1</td><td>1     </td><td>0     </td></tr>\n",
       "\t<tr><th scope=row>4567</th><td>6519  </td><td>53    </td><td>0     </td><td>1     </td><td>0     </td><td>0     </td><td>999   </td><td>0     </td><td>0     </td><td>-1.8  </td><td>93.075</td><td>1.479 </td><td>5099.1</td><td>2     </td><td>0     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       "  & client\\_id & age & job\\_unknown & contact\\_cellular & contact\\_telephone & month\\_aug & pdays & previous & poutcome\\_success & emp\\_var\\_rate & cons\\_price\\_idx & euribor3m & nr\\_employed & age\\_binned & subscribe\\\\\n",
       "\\hline\n",
       "\t1017 & 1472   & 44     & 0      & 1      & 0      & 0      & 999    & 0      & 0      &  1.4   & 93.918 & 4.960  & 5228.1 & 2      & 0     \\\\\n",
       "\t4775 & 6809   & 35     & 0      & 0      & 1      & 0      & 999    & 0      & 0      & -1.8   & 92.893 & 1.281  & 5099.1 & 1      & 0     \\\\\n",
       "\t2177 & 3103   & 35     & 1      & 0      & 1      & 0      & 999    & 0      & 0      &  1.1   & 93.994 & 4.855  & 5191.0 & 1      & 0     \\\\\n",
       "\t5026 & 7194   & 44     & 0      & 1      & 0      & 0      & 999    & 0      & 0      & -1.8   & 92.893 & 1.299  & 5099.1 & 2      & 0     \\\\\n",
       "\t1533 & 2195   & 32     & 0      & 0      & 1      & 0      & 999    & 0      & 0      &  1.4   & 93.918 & 4.968  & 5228.1 & 1      & 0     \\\\\n",
       "\t4567 & 6519   & 53     & 0      & 1      & 0      & 0      & 999    & 0      & 0      & -1.8   & 93.075 & 1.479  & 5099.1 & 2      & 0     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | client_id | age | job_unknown | contact_cellular | contact_telephone | month_aug | pdays | previous | poutcome_success | emp_var_rate | cons_price_idx | euribor3m | nr_employed | age_binned | subscribe |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1017 | 1472   | 44     | 0      | 1      | 0      | 0      | 999    | 0      | 0      |  1.4   | 93.918 | 4.960  | 5228.1 | 2      | 0      |\n",
       "| 4775 | 6809   | 35     | 0      | 0      | 1      | 0      | 999    | 0      | 0      | -1.8   | 92.893 | 1.281  | 5099.1 | 1      | 0      |\n",
       "| 2177 | 3103   | 35     | 1      | 0      | 1      | 0      | 999    | 0      | 0      |  1.1   | 93.994 | 4.855  | 5191.0 | 1      | 0      |\n",
       "| 5026 | 7194   | 44     | 0      | 1      | 0      | 0      | 999    | 0      | 0      | -1.8   | 92.893 | 1.299  | 5099.1 | 2      | 0      |\n",
       "| 1533 | 2195   | 32     | 0      | 0      | 1      | 0      | 999    | 0      | 0      |  1.4   | 93.918 | 4.968  | 5228.1 | 1      | 0      |\n",
       "| 4567 | 6519   | 53     | 0      | 1      | 0      | 0      | 999    | 0      | 0      | -1.8   | 93.075 | 1.479  | 5099.1 | 2      | 0      |\n",
       "\n"
      ],
      "text/plain": [
       "     client_id age job_unknown contact_cellular contact_telephone month_aug\n",
       "1017 1472      44  0           1                0                 0        \n",
       "4775 6809      35  0           0                1                 0        \n",
       "2177 3103      35  1           0                1                 0        \n",
       "5026 7194      44  0           1                0                 0        \n",
       "1533 2195      32  0           0                1                 0        \n",
       "4567 6519      53  0           1                0                 0        \n",
       "     pdays previous poutcome_success emp_var_rate cons_price_idx euribor3m\n",
       "1017 999   0        0                 1.4         93.918         4.960    \n",
       "4775 999   0        0                -1.8         92.893         1.281    \n",
       "2177 999   0        0                 1.1         93.994         4.855    \n",
       "5026 999   0        0                -1.8         92.893         1.299    \n",
       "1533 999   0        0                 1.4         93.918         4.968    \n",
       "4567 999   0        0                -1.8         93.075         1.479    \n",
       "     nr_employed age_binned subscribe\n",
       "1017 5228.1      2          0        \n",
       "4775 5099.1      1          0        \n",
       "2177 5191.0      1          0        \n",
       "5026 5099.1      2          0        \n",
       "1533 5228.1      1          0        \n",
       "4567 5099.1      2          0        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output predicted file\n",
    "\n",
    "write.csv(test_data, 'FinalBaseTable.csv', row.names=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling: cross-validation\n",
      "Measures:             auc.train   auc.test    \n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"[Resample] iter 1:    0.7854166   0.7873739   \n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"[Resample] iter 2:    0.7920924   0.7529193   \n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"[Resample] iter 3:    0.7865604   0.7745222   \n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"[Resample] iter 4:    0.7794546   0.8004047   \n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"[Resample] iter 5:    0.7867314   0.7699044   \n",
      "\n",
      "\n",
      "Aggregated Result: auc.test.mean=0.7770249,auc.train.mean=0.7860511\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up cross-validation\n",
    "rdesc = makeResampleDesc(\"CV\", iters=5, predict=\"both\")\n",
    "\n",
    "# Define the model\n",
    "learner <- makeLearner(\"classif.logreg\", predict.type=\"prob\", fix.factors.prediction=T)\n",
    "\n",
    "# Define the task\n",
    "train_task <- makeClassifTask(id=\"bank_train\", data=train_processed[, -1], target=\"subscribe\")\n",
    "\n",
    "# Set hyper parameter tuning\n",
    "tune_params <- makeParamSet(\n",
    ")\n",
    "ctrl = makeTuneControlGrid()\n",
    "\n",
    "# Run the hyper parameter tuning with k-fold CV\n",
    "if (length(tune_params$pars) > 0) {\n",
    "    # Run parameter tuning\n",
    "    res <- tuneParams(learner, task=train_task, resampling=rdesc,\n",
    "      par.set=tune_params, control=ctrl, measures=list(mlr::auc))\n",
    "    \n",
    "    # Extract best model\n",
    "    best_learner <- res$learner\n",
    "    \n",
    "} else {\n",
    "    # Simple cross-validation\n",
    "    res <- resample(learner, train_task, rdesc, measures=list(mlr::auc, setAggregation(mlr::auc, train.mean)))\n",
    "    \n",
    "    # No parameter for tuning, only 1 best learner\n",
    "    best_learner <- learner\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with tbe best hyper-parameters\n",
    "best_md <- mlr::train(best_learner, train_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>auc:</strong> 0.801028674837147"
      ],
      "text/latex": [
       "\\textbf{auc:} 0.801028674837147"
      ],
      "text/markdown": [
       "**auc:** 0.801028674837147"
      ],
      "text/plain": [
       "      auc \n",
       "0.8010287 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on test data\n",
    "pred <- predict(best_md, newdata=test_processed[, -1])\n",
    "performance(pred, measures=mlr::auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction: 3000 observations\n",
       "predict.type: prob\n",
       "threshold: 0=0.50,1=0.50\n",
       "time: 0.02\n",
       "     prob.0     prob.1 response\n",
       "1 0.9028804 0.09711956        0\n",
       "2 0.9516697 0.04833025        0\n",
       "3 0.8597326 0.14026743        0\n",
       "4 0.9749095 0.02509051        0\n",
       "5 0.9560173 0.04398269        0\n",
       "6 0.9483242 0.05167577        0\n",
       "... (#rows: 3000, #cols: 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on test (holdout) data\n",
    "pred <- predict(best_md, newdata=test_holdout_processed[, -1])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output predicted file\n",
    "output <- data.frame(client_id=test_data$client_id, subscribe=pred$data$prob.1)\n",
    "write.csv(output, 'logreg.csv', row.names=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Tune] Started tuning learner classif.randomForest for parameter set:\n",
      "            Type len Def    Constr Req Tunable Trafo\n",
      "ntree    integer   -   - 50 to 500   -    TRUE     -\n",
      "mtry     integer   -   -   3 to 10   -    TRUE     -\n",
      "nodesize integer   -   -  10 to 50   -    TRUE     -\n",
      "With control class: TuneControlRandom\n",
      "Imputation value: -0\n",
      "[Tune-x] 1: ntree=258; mtry=7; nodesize=48\n",
      "[Tune-y] 1: auc.test.mean=0.7610168; time: 0.2 min\n",
      "[Tune-x] 2: ntree=278; mtry=7; nodesize=17\n",
      "[Tune-y] 2: auc.test.mean=0.7652011; time: 0.2 min\n",
      "[Tune-x] 3: ntree=182; mtry=5; nodesize=36\n",
      "[Tune-y] 3: auc.test.mean=0.7626760; time: 0.1 min\n",
      "[Tune-x] 4: ntree=138; mtry=6; nodesize=16\n",
      "[Tune-y] 4: auc.test.mean=0.7582768; time: 0.1 min\n",
      "[Tune-x] 5: ntree=281; mtry=6; nodesize=38\n",
      "[Tune-y] 5: auc.test.mean=0.7611588; time: 0.2 min\n",
      "[Tune-x] 6: ntree=121; mtry=7; nodesize=36\n",
      "[Tune-y] 6: auc.test.mean=0.7607376; time: 0.1 min\n",
      "[Tune-x] 7: ntree=310; mtry=7; nodesize=36\n",
      "[Tune-y] 7: auc.test.mean=0.7663135; time: 0.2 min\n",
      "[Tune-x] 8: ntree=271; mtry=7; nodesize=23\n",
      "[Tune-y] 8: auc.test.mean=0.7607222; time: 0.2 min\n",
      "[Tune-x] 9: ntree=448; mtry=6; nodesize=27\n",
      "[Tune-y] 9: auc.test.mean=0.7642676; time: 0.4 min\n",
      "[Tune-x] 10: ntree=476; mtry=5; nodesize=26\n",
      "[Tune-y] 10: auc.test.mean=0.7650456; time: 0.4 min\n",
      "[Tune] Result: ntree=310; mtry=7; nodesize=36 : auc.test.mean=0.7663135\n"
     ]
    }
   ],
   "source": [
    "# Set up cross-validation\n",
    "rdesc = makeResampleDesc(\"CV\", iters=10)\n",
    "\n",
    "# Define the model\n",
    "learner <- makeLearner(\"classif.randomForest\", predict.type=\"prob\", fix.factors.prediction=T)\n",
    "\n",
    "# Define the task\n",
    "train_task <- makeClassifTask(id=\"bank_train\", data=train_processed[, -1], target=\"subscribe\")\n",
    "\n",
    "# Set hyper parameter tuning\n",
    "tune_params <- makeParamSet(\n",
    "      makeIntegerParam('ntree', lower = 50, upper = 500),\n",
    "      makeIntegerParam('mtry', lower = 3, upper = 10),\n",
    "      makeIntegerParam('nodesize', lower = 10, upper = 50)\n",
    ")\n",
    "ctrl = makeTuneControlRandom(maxit = 10L)\n",
    "\n",
    "# Run the hyper parameter tuning with k-fold CV\n",
    "if (length(tune_params$pars) > 0) {\n",
    "    # Run parameter tuning\n",
    "    res <- tuneParams(learner, task=train_task, resampling=rdesc,\n",
    "      par.set=tune_params, control=ctrl, measures=list(mlr::auc))\n",
    "    \n",
    "    # Extract best model\n",
    "    best_learner <- res$learner\n",
    "    \n",
    "} else {\n",
    "    # Simple cross-validation\n",
    "    res <- resample(learner, train_task, rdesc, measures=list(mlr::auc))\n",
    "    \n",
    "    # No parameter for tuning, only 1 best learner\n",
    "    best_learner <- learner\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with tbe best hyper-parameters\n",
    "best_md <- mlr::train(best_learner, train_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>auc:</strong> 0.784738818196302"
      ],
      "text/latex": [
       "\\textbf{auc:} 0.784738818196302"
      ],
      "text/markdown": [
       "**auc:** 0.784738818196302"
      ],
      "text/plain": [
       "      auc \n",
       "0.7847388 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on test data\n",
    "pred <- predict(best_md, newdata=test_processed[, -1])\n",
    "performance(pred, measures=mlr::auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction: 3000 observations\n",
       "predict.type: prob\n",
       "threshold: 0=0.50,1=0.50\n",
       "time: 0.09\n",
       "  prob.0 prob.1 response\n",
       "1  1.000  0.000        0\n",
       "2  1.000  0.000        0\n",
       "3  0.686  0.314        0\n",
       "4  0.998  0.002        0\n",
       "5  0.994  0.006        0\n",
       "6  1.000  0.000        0\n",
       "... (#rows: 3000, #cols: 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on test data\n",
    "pred <- predict(best_md, newdata=test_holdout_processed[, -1])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output predicted file\n",
    "output <- data.frame(client_id=test_data$client_id, subscribe=pred$data$prob.1)\n",
    "write.csv(output, 'randomforest.csv', row.names=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Xtreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t5250 obs. of  15 variables:\n",
      " $ client_id        : int  1472 6809 3103 7194 2195 6519 3340 384 5774 7593 ...\n",
      " $ age              : int  44 35 35 44 32 53 28 51 36 62 ...\n",
      " $ job_unknown      : int  0 0 1 0 0 0 0 0 0 0 ...\n",
      " $ contact_cellular : int  1 0 0 1 0 1 1 1 1 1 ...\n",
      " $ contact_telephone: int  0 1 1 0 1 0 0 0 0 0 ...\n",
      " $ month_aug        : int  0 0 0 0 0 0 0 0 1 1 ...\n",
      " $ pdays            : int  999 999 999 999 999 999 999 999 999 999 ...\n",
      " $ previous         : int  0 0 0 0 0 0 0 0 0 1 ...\n",
      " $ poutcome_success : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ emp_var_rate     : num  1.4 -1.8 1.1 -1.8 1.4 -1.8 -1.8 -1.7 1.4 -2.9 ...\n",
      " $ cons_price_idx   : num  93.9 92.9 94 92.9 93.9 ...\n",
      " $ euribor3m        : num  4.96 1.28 4.86 1.3 4.97 ...\n",
      " $ nr_employed      : num  5228 5099 5191 5099 5228 ...\n",
      " $ age_binned       : num  2 1 1 2 1 2 1 2 1 3 ...\n",
      " $ subscribe        : int  0 0 0 0 0 0 0 0 0 0 ...\n"
     ]
    }
   ],
   "source": [
    "str(train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Tune] Started tuning learner classif.xgboost for parameter set:\n",
      "                    Type len Def       Constr Req Tunable Trafo\n",
      "nrounds          integer   -   -   200 to 600   -    TRUE     -\n",
      "max_depth        integer   -   -      3 to 20   -    TRUE     -\n",
      "lambda           numeric   -   -  0.55 to 0.6   -    TRUE     -\n",
      "eta              numeric   -   - 0.001 to 0.5   -    TRUE     -\n",
      "subsample        numeric   -   -   0.1 to 0.8   -    TRUE     -\n",
      "min_child_weight numeric   -   -     0.1 to 5   -    TRUE     -\n",
      "colsample_bytree numeric   -   -   0.2 to 0.8   -    TRUE     -\n",
      "With control class: TuneControlRandom\n",
      "Imputation value: -0\n",
      "[Tune-x] 1: nrounds=543; max_depth=14; lambda=0.586; eta=0.291; subsample=0.797; min_child_weight=4.16; colsample_bytree=0.325\n",
      "[Tune-y] 1: auc.test.mean=0.6996991; time: 0.4 min\n",
      "[Tune-x] 2: nrounds=481; max_depth=6; lambda=0.579; eta=0.49; subsample=0.146; min_child_weight=1.74; colsample_bytree=0.579\n",
      "[Tune-y] 2: auc.test.mean=0.6658887; time: 0.3 min\n",
      "[Tune-x] 3: nrounds=438; max_depth=18; lambda=0.594; eta=0.0811; subsample=0.353; min_child_weight=4.89; colsample_bytree=0.228\n",
      "[Tune-y] 3: auc.test.mean=0.7735421; time: 0.2 min\n",
      "[Tune-x] 4: nrounds=302; max_depth=8; lambda=0.555; eta=0.236; subsample=0.349; min_child_weight=3.24; colsample_bytree=0.532\n",
      "[Tune-y] 4: auc.test.mean=0.7285882; time: 0.2 min\n",
      "[Tune-x] 5: nrounds=350; max_depth=17; lambda=0.55; eta=0.00705; subsample=0.263; min_child_weight=1.84; colsample_bytree=0.401\n",
      "[Tune-y] 5: auc.test.mean=0.7843299; time: 0.3 min\n",
      "[Tune-x] 6: nrounds=382; max_depth=12; lambda=0.567; eta=0.48; subsample=0.465; min_child_weight=1.35; colsample_bytree=0.574\n",
      "[Tune-y] 6: auc.test.mean=0.6717152; time: 0.4 min\n",
      "[Tune-x] 7: nrounds=226; max_depth=16; lambda=0.585; eta=0.454; subsample=0.238; min_child_weight=3.64; colsample_bytree=0.521\n",
      "[Tune-y] 7: auc.test.mean=0.7186198; time: 0.2 min\n",
      "[Tune-x] 8: nrounds=212; max_depth=8; lambda=0.585; eta=0.448; subsample=0.236; min_child_weight=1.77; colsample_bytree=0.395\n",
      "[Tune-y] 8: auc.test.mean=0.6919565; time: 0.2 min\n",
      "[Tune-x] 9: nrounds=299; max_depth=11; lambda=0.56; eta=0.16; subsample=0.702; min_child_weight=2.39; colsample_bytree=0.253\n",
      "[Tune-y] 9: auc.test.mean=0.7304821; time: 0.2 min\n",
      "[Tune-x] 10: nrounds=598; max_depth=3; lambda=0.575; eta=0.419; subsample=0.535; min_child_weight=3.77; colsample_bytree=0.659\n",
      "[Tune-y] 10: auc.test.mean=0.7199239; time: 0.2 min\n",
      "[Tune-x] 11: nrounds=341; max_depth=7; lambda=0.578; eta=0.461; subsample=0.106; min_child_weight=0.96; colsample_bytree=0.246\n",
      "[Tune-y] 11: auc.test.mean=0.6987872; time: 0.2 min\n",
      "[Tune-x] 12: nrounds=395; max_depth=3; lambda=0.571; eta=0.0616; subsample=0.439; min_child_weight=0.571; colsample_bytree=0.732\n",
      "[Tune-y] 12: auc.test.mean=0.7764221; time: 0.2 min\n",
      "[Tune-x] 13: nrounds=313; max_depth=18; lambda=0.556; eta=0.287; subsample=0.501; min_child_weight=0.919; colsample_bytree=0.325\n",
      "[Tune-y] 13: auc.test.mean=0.6831477; time: 0.3 min\n",
      "[Tune-x] 14: nrounds=227; max_depth=16; lambda=0.58; eta=0.305; subsample=0.117; min_child_weight=2.42; colsample_bytree=0.291\n",
      "[Tune-y] 14: auc.test.mean=0.7566698; time: 0.1 min\n",
      "[Tune-x] 15: nrounds=544; max_depth=9; lambda=0.595; eta=0.33; subsample=0.655; min_child_weight=3.5; colsample_bytree=0.265\n",
      "[Tune-y] 15: auc.test.mean=0.7139439; time: 0.4 min\n",
      "[Tune-x] 16: nrounds=533; max_depth=12; lambda=0.579; eta=0.45; subsample=0.461; min_child_weight=0.681; colsample_bytree=0.232\n",
      "[Tune-y] 16: auc.test.mean=0.6628564; time: 0.4 min\n",
      "[Tune-x] 17: nrounds=471; max_depth=12; lambda=0.553; eta=0.314; subsample=0.666; min_child_weight=3.84; colsample_bytree=0.587\n",
      "[Tune-y] 17: auc.test.mean=0.6929494; time: 0.5 min\n",
      "[Tune-x] 18: nrounds=556; max_depth=5; lambda=0.574; eta=0.215; subsample=0.155; min_child_weight=0.854; colsample_bytree=0.689\n",
      "[Tune-y] 18: auc.test.mean=0.7008978; time: 0.4 min\n",
      "[Tune-x] 19: nrounds=322; max_depth=5; lambda=0.565; eta=0.196; subsample=0.109; min_child_weight=3.52; colsample_bytree=0.222\n",
      "[Tune-y] 19: auc.test.mean=0.7697836; time: 0.1 min\n",
      "[Tune-x] 20: nrounds=573; max_depth=4; lambda=0.59; eta=0.24; subsample=0.144; min_child_weight=4.77; colsample_bytree=0.342\n",
      "[Tune-y] 20: auc.test.mean=0.7567145; time: 0.3 min\n",
      "[Tune-x] 21: nrounds=260; max_depth=17; lambda=0.593; eta=0.477; subsample=0.544; min_child_weight=4.7; colsample_bytree=0.73\n",
      "[Tune-y] 21: auc.test.mean=0.6900585; time: 0.3 min\n",
      "[Tune-x] 22: nrounds=547; max_depth=13; lambda=0.591; eta=0.151; subsample=0.17; min_child_weight=2.81; colsample_bytree=0.407\n",
      "[Tune-y] 22: auc.test.mean=0.7275273; time: 0.4 min\n",
      "[Tune-x] 23: nrounds=293; max_depth=16; lambda=0.567; eta=0.298; subsample=0.408; min_child_weight=2.57; colsample_bytree=0.368\n",
      "[Tune-y] 23: auc.test.mean=0.7084425; time: 0.3 min\n",
      "[Tune-x] 24: nrounds=359; max_depth=18; lambda=0.598; eta=0.148; subsample=0.668; min_child_weight=1.14; colsample_bytree=0.335\n",
      "[Tune-y] 24: auc.test.mean=0.7000498; time: 0.4 min\n",
      "[Tune-x] 25: nrounds=569; max_depth=6; lambda=0.559; eta=0.0233; subsample=0.769; min_child_weight=3.28; colsample_bytree=0.329\n",
      "[Tune-y] 25: auc.test.mean=0.7722286; time: 0.3 min\n",
      "[Tune-x] 26: nrounds=485; max_depth=14; lambda=0.568; eta=0.136; subsample=0.759; min_child_weight=1.76; colsample_bytree=0.424\n",
      "[Tune-y] 26: auc.test.mean=0.6995080; time: 0.5 min\n",
      "[Tune-x] 27: nrounds=591; max_depth=10; lambda=0.583; eta=0.253; subsample=0.418; min_child_weight=3.42; colsample_bytree=0.419\n",
      "[Tune-y] 27: auc.test.mean=0.6949494; time: 0.5 min\n",
      "[Tune-x] 28: nrounds=250; max_depth=5; lambda=0.581; eta=0.249; subsample=0.518; min_child_weight=1.8; colsample_bytree=0.326\n",
      "[Tune-y] 28: auc.test.mean=0.7411117; time: 0.1 min\n",
      "[Tune-x] 29: nrounds=508; max_depth=10; lambda=0.563; eta=0.184; subsample=0.655; min_child_weight=2.53; colsample_bytree=0.312\n",
      "[Tune-y] 29: auc.test.mean=0.7013085; time: 0.4 min\n",
      "[Tune-x] 30: nrounds=439; max_depth=11; lambda=0.563; eta=0.0812; subsample=0.356; min_child_weight=4.47; colsample_bytree=0.364\n",
      "[Tune-y] 30: auc.test.mean=0.7605218; time: 0.3 min\n",
      "[Tune-x] 31: nrounds=533; max_depth=20; lambda=0.553; eta=0.341; subsample=0.287; min_child_weight=2.68; colsample_bytree=0.746\n",
      "[Tune-y] 31: auc.test.mean=0.6788490; time: 0.5 min\n",
      "[Tune-x] 32: nrounds=231; max_depth=10; lambda=0.592; eta=0.132; subsample=0.533; min_child_weight=0.795; colsample_bytree=0.668\n",
      "[Tune-y] 32: auc.test.mean=0.7090555; time: 0.3 min\n",
      "[Tune-x] 33: nrounds=451; max_depth=3; lambda=0.596; eta=0.306; subsample=0.551; min_child_weight=2.04; colsample_bytree=0.478\n",
      "[Tune-y] 33: auc.test.mean=0.7468117; time: 0.2 min\n",
      "[Tune-x] 34: nrounds=349; max_depth=18; lambda=0.583; eta=0.221; subsample=0.556; min_child_weight=3.16; colsample_bytree=0.556\n",
      "[Tune-y] 34: auc.test.mean=0.7014128; time: 0.4 min\n",
      "[Tune-x] 35: nrounds=454; max_depth=19; lambda=0.58; eta=0.459; subsample=0.165; min_child_weight=2.95; colsample_bytree=0.793\n",
      "[Tune-y] 35: auc.test.mean=0.6774424; time: 0.3 min\n",
      "[Tune-x] 36: nrounds=316; max_depth=5; lambda=0.591; eta=0.296; subsample=0.43; min_child_weight=1.13; colsample_bytree=0.511\n",
      "[Tune-y] 36: auc.test.mean=0.7057853; time: 0.2 min\n",
      "[Tune-x] 37: nrounds=343; max_depth=3; lambda=0.585; eta=0.0499; subsample=0.698; min_child_weight=3.36; colsample_bytree=0.417\n",
      "[Tune-y] 37: auc.test.mean=0.7790806; time: 0.1 min\n",
      "[Tune-x] 38: nrounds=386; max_depth=11; lambda=0.571; eta=0.189; subsample=0.517; min_child_weight=4.25; colsample_bytree=0.378\n",
      "[Tune-y] 38: auc.test.mean=0.7383531; time: 0.3 min\n",
      "[Tune-x] 39: nrounds=306; max_depth=19; lambda=0.563; eta=0.305; subsample=0.728; min_child_weight=2.14; colsample_bytree=0.35\n",
      "[Tune-y] 39: auc.test.mean=0.6937053; time: 0.3 min\n",
      "[Tune-x] 40: nrounds=535; max_depth=3; lambda=0.593; eta=0.408; subsample=0.572; min_child_weight=0.786; colsample_bytree=0.557\n",
      "[Tune-y] 40: auc.test.mean=0.7153776; time: 0.2 min\n",
      "[Tune-x] 41: nrounds=242; max_depth=11; lambda=0.576; eta=0.398; subsample=0.574; min_child_weight=4.49; colsample_bytree=0.765\n",
      "[Tune-y] 41: auc.test.mean=0.6996892; time: 0.2 min\n",
      "[Tune-x] 42: nrounds=449; max_depth=13; lambda=0.559; eta=0.148; subsample=0.738; min_child_weight=0.603; colsample_bytree=0.274\n",
      "[Tune-y] 42: auc.test.mean=0.7003207; time: 0.4 min\n",
      "[Tune-x] 43: nrounds=229; max_depth=11; lambda=0.581; eta=0.218; subsample=0.133; min_child_weight=0.782; colsample_bytree=0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Tune-y] 43: auc.test.mean=0.6978201; time: 0.2 min\n",
      "[Tune-x] 44: nrounds=579; max_depth=8; lambda=0.588; eta=0.0941; subsample=0.174; min_child_weight=4.69; colsample_bytree=0.565\n",
      "[Tune-y] 44: auc.test.mean=0.7633367; time: 0.4 min\n",
      "[Tune-x] 45: nrounds=344; max_depth=7; lambda=0.586; eta=0.0861; subsample=0.494; min_child_weight=4.6; colsample_bytree=0.53\n",
      "[Tune-y] 45: auc.test.mean=0.7571901; time: 0.2 min\n",
      "[Tune-x] 46: nrounds=274; max_depth=16; lambda=0.578; eta=0.0443; subsample=0.448; min_child_weight=3.9; colsample_bytree=0.495\n",
      "[Tune-y] 46: auc.test.mean=0.7685038; time: 0.3 min\n",
      "[Tune-x] 47: nrounds=577; max_depth=15; lambda=0.589; eta=0.26; subsample=0.503; min_child_weight=2.41; colsample_bytree=0.526\n",
      "[Tune-y] 47: auc.test.mean=0.6878760; time: 0.6 min\n",
      "[Tune-x] 48: nrounds=586; max_depth=18; lambda=0.563; eta=0.197; subsample=0.26; min_child_weight=1.36; colsample_bytree=0.373\n",
      "[Tune-y] 48: auc.test.mean=0.7088438; time: 0.5 min\n",
      "[Tune-x] 49: nrounds=246; max_depth=6; lambda=0.566; eta=0.0499; subsample=0.727; min_child_weight=3.5; colsample_bytree=0.575\n",
      "[Tune-y] 49: auc.test.mean=0.7701055; time: 0.2 min\n",
      "[Tune-x] 50: nrounds=253; max_depth=8; lambda=0.564; eta=0.143; subsample=0.262; min_child_weight=3.82; colsample_bytree=0.645\n",
      "[Tune-y] 50: auc.test.mean=0.7457920; time: 0.2 min\n",
      "[Tune-x] 51: nrounds=302; max_depth=11; lambda=0.57; eta=0.465; subsample=0.536; min_child_weight=0.466; colsample_bytree=0.226\n",
      "[Tune-y] 51: auc.test.mean=0.6834237; time: 0.2 min\n",
      "[Tune-x] 52: nrounds=369; max_depth=8; lambda=0.597; eta=0.0928; subsample=0.269; min_child_weight=1.97; colsample_bytree=0.601\n",
      "[Tune-y] 52: auc.test.mean=0.7379025; time: 0.3 min\n",
      "[Tune-x] 53: nrounds=487; max_depth=20; lambda=0.553; eta=0.494; subsample=0.428; min_child_weight=0.501; colsample_bytree=0.795\n",
      "[Tune-y] 53: auc.test.mean=0.7028368; time: 0.6 min\n",
      "[Tune-x] 54: nrounds=525; max_depth=3; lambda=0.59; eta=0.213; subsample=0.224; min_child_weight=1.89; colsample_bytree=0.549\n",
      "[Tune-y] 54: auc.test.mean=0.7462445; time: 0.2 min\n",
      "[Tune-x] 55: nrounds=264; max_depth=9; lambda=0.599; eta=0.258; subsample=0.352; min_child_weight=0.237; colsample_bytree=0.23\n",
      "[Tune-y] 55: auc.test.mean=0.7158956; time: 0.2 min\n",
      "[Tune-x] 56: nrounds=408; max_depth=6; lambda=0.596; eta=0.265; subsample=0.392; min_child_weight=3.28; colsample_bytree=0.347\n",
      "[Tune-y] 56: auc.test.mean=0.7300436; time: 0.2 min\n",
      "[Tune-x] 57: nrounds=250; max_depth=12; lambda=0.556; eta=0.466; subsample=0.369; min_child_weight=3.58; colsample_bytree=0.281\n",
      "[Tune-y] 57: auc.test.mean=0.7305976; time: 0.2 min\n",
      "[Tune-x] 58: nrounds=322; max_depth=5; lambda=0.555; eta=0.115; subsample=0.363; min_child_weight=3.95; colsample_bytree=0.479\n",
      "[Tune-y] 58: auc.test.mean=0.7621490; time: 0.2 min\n",
      "[Tune-x] 59: nrounds=363; max_depth=3; lambda=0.58; eta=0.486; subsample=0.389; min_child_weight=0.859; colsample_bytree=0.558\n",
      "[Tune-y] 59: auc.test.mean=0.7116900; time: 0.1 min\n",
      "[Tune-x] 60: nrounds=215; max_depth=14; lambda=0.563; eta=0.262; subsample=0.167; min_child_weight=0.378; colsample_bytree=0.615\n",
      "[Tune-y] 60: auc.test.mean=0.6970880; time: 0.2 min\n",
      "[Tune-x] 61: nrounds=358; max_depth=4; lambda=0.571; eta=0.00486; subsample=0.485; min_child_weight=2.48; colsample_bytree=0.766\n",
      "[Tune-y] 61: auc.test.mean=0.7836179; time: 0.2 min\n",
      "[Tune-x] 62: nrounds=253; max_depth=3; lambda=0.597; eta=0.185; subsample=0.663; min_child_weight=1.68; colsample_bytree=0.545\n",
      "[Tune-y] 62: auc.test.mean=0.7652728; time: 0.1 min\n",
      "[Tune-x] 63: nrounds=277; max_depth=8; lambda=0.591; eta=0.439; subsample=0.562; min_child_weight=1.48; colsample_bytree=0.518\n",
      "[Tune-y] 63: auc.test.mean=0.6752686; time: 0.2 min\n",
      "[Tune-x] 64: nrounds=465; max_depth=5; lambda=0.573; eta=0.171; subsample=0.61; min_child_weight=3.79; colsample_bytree=0.387\n",
      "[Tune-y] 64: auc.test.mean=0.7341013; time: 0.3 min\n",
      "[Tune-x] 65: nrounds=457; max_depth=6; lambda=0.556; eta=0.309; subsample=0.544; min_child_weight=4.48; colsample_bytree=0.628\n",
      "[Tune-y] 65: auc.test.mean=0.7018488; time: 0.3 min\n",
      "[Tune-x] 66: nrounds=214; max_depth=18; lambda=0.598; eta=0.181; subsample=0.448; min_child_weight=1.66; colsample_bytree=0.257\n",
      "[Tune-y] 66: auc.test.mean=0.7351224; time: 0.2 min\n",
      "[Tune-x] 67: nrounds=567; max_depth=17; lambda=0.552; eta=0.441; subsample=0.734; min_child_weight=1.7; colsample_bytree=0.4\n",
      "[Tune-y] 67: auc.test.mean=0.6763233; time: 0.6 min\n",
      "[Tune-x] 68: nrounds=598; max_depth=9; lambda=0.593; eta=0.444; subsample=0.197; min_child_weight=2.74; colsample_bytree=0.61\n",
      "[Tune-y] 68: auc.test.mean=0.6802525; time: 0.4 min\n",
      "[Tune-x] 69: nrounds=541; max_depth=12; lambda=0.586; eta=0.443; subsample=0.126; min_child_weight=4.47; colsample_bytree=0.585\n",
      "[Tune-y] 69: auc.test.mean=0.7406857; time: 0.3 min\n",
      "[Tune-x] 70: nrounds=411; max_depth=7; lambda=0.577; eta=0.37; subsample=0.234; min_child_weight=0.872; colsample_bytree=0.34\n",
      "[Tune-y] 70: auc.test.mean=0.6830455; time: 0.3 min\n",
      "[Tune-x] 71: nrounds=422; max_depth=16; lambda=0.561; eta=0.0192; subsample=0.29; min_child_weight=2.59; colsample_bytree=0.229\n",
      "[Tune-y] 71: auc.test.mean=0.7834076; time: 0.2 min\n",
      "[Tune-x] 72: nrounds=460; max_depth=8; lambda=0.573; eta=0.309; subsample=0.372; min_child_weight=1.55; colsample_bytree=0.281\n",
      "[Tune-y] 72: auc.test.mean=0.7010225; time: 0.3 min\n",
      "[Tune-x] 73: nrounds=558; max_depth=3; lambda=0.585; eta=0.479; subsample=0.348; min_child_weight=3.25; colsample_bytree=0.237\n",
      "[Tune-y] 73: auc.test.mean=0.7435932; time: 0.2 min\n",
      "[Tune-x] 74: nrounds=371; max_depth=12; lambda=0.583; eta=0.488; subsample=0.394; min_child_weight=1.53; colsample_bytree=0.466\n",
      "[Tune-y] 74: auc.test.mean=0.6776037; time: 0.4 min\n",
      "[Tune-x] 75: nrounds=317; max_depth=7; lambda=0.569; eta=0.353; subsample=0.294; min_child_weight=2.42; colsample_bytree=0.784\n",
      "[Tune-y] 75: auc.test.mean=0.6855064; time: 0.2 min\n",
      "[Tune-x] 76: nrounds=362; max_depth=14; lambda=0.57; eta=0.0463; subsample=0.418; min_child_weight=0.714; colsample_bytree=0.737\n",
      "[Tune-y] 76: auc.test.mean=0.7159619; time: 0.5 min\n",
      "[Tune-x] 77: nrounds=518; max_depth=17; lambda=0.583; eta=0.267; subsample=0.306; min_child_weight=0.641; colsample_bytree=0.562\n",
      "[Tune-y] 77: auc.test.mean=0.6757028; time: 0.6 min\n",
      "[Tune-x] 78: nrounds=586; max_depth=4; lambda=0.584; eta=0.491; subsample=0.298; min_child_weight=4.04; colsample_bytree=0.24\n",
      "[Tune-y] 78: auc.test.mean=0.7327657; time: 0.3 min\n",
      "[Tune-x] 79: nrounds=332; max_depth=7; lambda=0.554; eta=0.0544; subsample=0.586; min_child_weight=0.569; colsample_bytree=0.614\n",
      "[Tune-y] 79: auc.test.mean=0.7406705; time: 0.3 min\n",
      "[Tune-x] 80: nrounds=355; max_depth=8; lambda=0.58; eta=0.494; subsample=0.593; min_child_weight=1.6; colsample_bytree=0.629\n",
      "[Tune-y] 80: auc.test.mean=0.6709910; time: 0.3 min\n",
      "[Tune-x] 81: nrounds=544; max_depth=11; lambda=0.577; eta=0.485; subsample=0.426; min_child_weight=3.76; colsample_bytree=0.754\n",
      "[Tune-y] 81: auc.test.mean=0.6736774; time: 0.5 min\n",
      "[Tune-x] 82: nrounds=492; max_depth=11; lambda=0.556; eta=0.296; subsample=0.27; min_child_weight=3.59; colsample_bytree=0.23\n",
      "[Tune-y] 82: auc.test.mean=0.7475960; time: 0.3 min\n",
      "[Tune-x] 83: nrounds=360; max_depth=8; lambda=0.561; eta=0.419; subsample=0.516; min_child_weight=3.63; colsample_bytree=0.772\n",
      "[Tune-y] 83: auc.test.mean=0.6872799; time: 0.3 min\n",
      "[Tune-x] 84: nrounds=516; max_depth=7; lambda=0.582; eta=0.418; subsample=0.459; min_child_weight=0.391; colsample_bytree=0.419\n",
      "[Tune-y] 84: auc.test.mean=0.6681953; time: 0.4 min\n",
      "[Tune-x] 85: nrounds=292; max_depth=15; lambda=0.588; eta=0.204; subsample=0.74; min_child_weight=0.298; colsample_bytree=0.28\n",
      "[Tune-y] 85: auc.test.mean=0.6936777; time: 0.3 min\n",
      "[Tune-x] 86: nrounds=239; max_depth=9; lambda=0.597; eta=0.024; subsample=0.461; min_child_weight=1.98; colsample_bytree=0.465\n",
      "[Tune-y] 86: auc.test.mean=0.7741980; time: 0.2 min\n",
      "[Tune-x] 87: nrounds=463; max_depth=3; lambda=0.558; eta=0.226; subsample=0.277; min_child_weight=4.59; colsample_bytree=0.665\n",
      "[Tune-y] 87: auc.test.mean=0.7558179; time: 0.2 min\n",
      "[Tune-x] 88: nrounds=330; max_depth=18; lambda=0.562; eta=0.436; subsample=0.321; min_child_weight=0.289; colsample_bytree=0.243\n",
      "[Tune-y] 88: auc.test.mean=0.6683871; time: 0.3 min\n",
      "[Tune-x] 89: nrounds=495; max_depth=12; lambda=0.6; eta=0.0315; subsample=0.584; min_child_weight=2.29; colsample_bytree=0.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Tune-y] 89: auc.test.mean=0.7379537; time: 0.6 min\n",
      "[Tune-x] 90: nrounds=423; max_depth=18; lambda=0.571; eta=0.386; subsample=0.629; min_child_weight=2.47; colsample_bytree=0.225\n",
      "[Tune-y] 90: auc.test.mean=0.7137530; time: 0.3 min\n",
      "[Tune-x] 91: nrounds=542; max_depth=15; lambda=0.555; eta=0.321; subsample=0.763; min_child_weight=0.289; colsample_bytree=0.641\n",
      "[Tune-y] 91: auc.test.mean=0.6949668; time: 0.7 min\n",
      "[Tune-x] 92: nrounds=450; max_depth=8; lambda=0.567; eta=0.0641; subsample=0.297; min_child_weight=3.22; colsample_bytree=0.706\n",
      "[Tune-y] 92: auc.test.mean=0.7444792; time: 0.4 min\n",
      "[Tune-x] 93: nrounds=352; max_depth=18; lambda=0.584; eta=0.388; subsample=0.252; min_child_weight=3.65; colsample_bytree=0.643\n",
      "[Tune-y] 93: auc.test.mean=0.7029743; time: 0.3 min\n",
      "[Tune-x] 94: nrounds=445; max_depth=11; lambda=0.6; eta=0.414; subsample=0.284; min_child_weight=4.83; colsample_bytree=0.445\n",
      "[Tune-y] 94: auc.test.mean=0.7206044; time: 0.3 min\n",
      "[Tune-x] 95: nrounds=301; max_depth=20; lambda=0.581; eta=0.41; subsample=0.325; min_child_weight=4.15; colsample_bytree=0.316\n",
      "[Tune-y] 95: auc.test.mean=0.7258723; time: 0.2 min\n",
      "[Tune-x] 96: nrounds=510; max_depth=5; lambda=0.557; eta=0.274; subsample=0.257; min_child_weight=3.36; colsample_bytree=0.578\n",
      "[Tune-y] 96: auc.test.mean=0.7217793; time: 0.3 min\n",
      "[Tune-x] 97: nrounds=492; max_depth=3; lambda=0.558; eta=0.176; subsample=0.797; min_child_weight=2; colsample_bytree=0.645\n",
      "[Tune-y] 97: auc.test.mean=0.7461630; time: 0.2 min\n",
      "[Tune-x] 98: nrounds=350; max_depth=11; lambda=0.582; eta=0.149; subsample=0.534; min_child_weight=1.5; colsample_bytree=0.389\n",
      "[Tune-y] 98: auc.test.mean=0.7055275; time: 0.3 min\n",
      "[Tune-x] 99: nrounds=465; max_depth=15; lambda=0.581; eta=0.143; subsample=0.693; min_child_weight=2.52; colsample_bytree=0.607\n",
      "[Tune-y] 99: auc.test.mean=0.6997097; time: 0.5 min\n",
      "[Tune-x] 100: nrounds=391; max_depth=18; lambda=0.58; eta=0.0228; subsample=0.368; min_child_weight=0.426; colsample_bytree=0.551\n",
      "[Tune-y] 100: auc.test.mean=0.7414465; time: 0.6 min\n",
      "[Tune] Result: nrounds=350; max_depth=17; lambda=0.55; eta=0.00705; subsample=0.263; min_child_weight=1.84; colsample_bytree=0.401 : auc.test.mean=0.7843299\n"
     ]
    }
   ],
   "source": [
    "# Set up cross-validation\n",
    "rdesc = makeResampleDesc(\"CV\", iters=10, predict=\"both\")\n",
    "\n",
    "# Define the model\n",
    "learner <- makeLearner(\"classif.xgboost\", predict.type=\"prob\")\n",
    "\n",
    "# Define the task\n",
    "train_task <- makeClassifTask(id=\"bank_train\", data=train_processed[, -1], target=\"subscribe\")\n",
    "\n",
    "# Set hyper parameter tuning\n",
    "tune_params <- makeParamSet(\n",
    "    \n",
    "    makeIntegerParam(\"nrounds\", lower = 200, upper = 600),\n",
    "    makeIntegerParam(\"max_depth\", lower = 3, upper = 20),\n",
    "    makeNumericParam(\"lambda\", lower = 0.55, upper = 0.60),\n",
    "    makeNumericParam(\"eta\", lower = 0.001, upper = 0.5),\n",
    "    makeNumericParam(\"subsample\", lower = 0.10, upper = 0.80),\n",
    "    makeNumericParam(\"min_child_weight\", lower = 0.10, upper = 5),\n",
    "    makeNumericParam(\"colsample_bytree\", lower = 0.2, upper = 0.8)\n",
    "    \n",
    ")\n",
    "ctrl = makeTuneControlRandom(maxit = 100L)\n",
    "\n",
    "# Run the hyper parameter tuning with k-fold CV\n",
    "if (length(tune_params$pars) > 0) {\n",
    "    # Run parameter tuning\n",
    "    res <- tuneParams(learner, task=train_task, resampling=rdesc,\n",
    "      par.set=tune_params, control=ctrl, measures=list(mlr::auc))\n",
    "    \n",
    "    # Extract best model\n",
    "    best_learner <- res$learner\n",
    "    \n",
    "} else {\n",
    "    # Simple cross-validation\n",
    "    res <- resample(learner, train_task, rdesc, measures=list(mlr::auc, setAggregation(mlr::auc, train.mean)))\n",
    "    \n",
    "    # No parameter for tuning, only 1 best learner\n",
    "    best_learner <- learner\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with tbe best hyper-parameters\n",
    "best_md <- mlr::train(best_learner, train_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>auc:</strong> 0.776365429070435"
      ],
      "text/latex": [
       "\\textbf{auc:} 0.776365429070435"
      ],
      "text/markdown": [
       "**auc:** 0.776365429070435"
      ],
      "text/plain": [
       "      auc \n",
       "0.7763654 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on test data\n",
    "pred <- predict(best_md, newdata=test_processed[, -1])\n",
    "performance(pred, measures=mlr::auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction: 3000 observations\n",
       "predict.type: prob\n",
       "threshold: 0=0.50,1=0.50\n",
       "time: 0.00\n",
       "     prob.1    prob.0 response\n",
       "1 0.3682989 0.6317011        0\n",
       "2 0.3682989 0.6317011        0\n",
       "3 0.4304538 0.5695462        0\n",
       "4 0.3682989 0.6317011        0\n",
       "5 0.3682989 0.6317011        0\n",
       "6 0.3682989 0.6317011        0\n",
       "... (#rows: 3000, #cols: 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on test data\n",
    "pred <- predict(best_md, newdata=test_holdout_processed[, -1])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output predicted file\n",
    "output <- data.frame(client_id=test_data$client_id, subscribe=pred$data$prob.1)\n",
    "write.csv(output, 'xgboost.csv', row.names=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Logit Leaf Model\n",
    "\n",
    "Reference:  \n",
    "\n",
    "De Caigny, A., Coussement, K., & De Bock, K. W. (2018). A new hybrid classification algorithm for customer churn prediction based on logistic regression and decision trees. European Journal of Operational Research, 269(2), 760-772."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LLM model and its parameters\n",
    "makeRLearner.classif.llm = function() {\n",
    "  makeRLearnerClassif(\n",
    "    cl = \"classif.llm\",\n",
    "    package = \"LLM\",\n",
    "    par.set = makeParamSet(\n",
    "      makeNumericLearnerParam(id=\"threshold_pruning\", default=0.25, tunable=T),\n",
    "      makeNumericLearnerParam(id=\"nbr_obs_leaf\", default=100, tunable=T)\n",
    "    ),\n",
    "    properties = c(\"twoclass\", \"numerics\", \"prob\"),\n",
    "    name = \"Logit Leaf Model\",\n",
    "    short.name = \"llm\",\n",
    "    note = \"Logit Leaf Model Classifier for Binary Classification.\"\n",
    "  )\n",
    "}\n",
    "\n",
    "# Define the train function for LLM\n",
    "trainLearner.classif.llm = function(.learner, .task, .subset, .weights=NULL, ...) {\n",
    "  \n",
    "  # Prepare data to train the LLM model\n",
    "  data = getTaskData(.task, .subset)\n",
    "  X <- data[, getTaskFeatureNames(.task)]\n",
    "  Y <- data[, getTaskTargetNames(.task)]\n",
    "  \n",
    "  # Train the LLM model\n",
    "  LLM::llm(X, Y, ...)\n",
    "}\n",
    "\n",
    "# Define the prediction function for LLM\n",
    "predictLearner.classif.llm = function(.learner, .model, .newdata, ...) {\n",
    "  \n",
    "  # Prepare test data for making prediction\n",
    "  X <- .newdata[, setdiff(names(.newdata), c(.model$task.desc$target))]\n",
    "  \n",
    "  # Make prediction using LLM model\n",
    "  p = LLM::predict.llm(.model$learner.model, X)\n",
    "  out <- data.frame(Y=p$probability, N=1-p$probability)\n",
    "  \n",
    "  return(as.matrix(out))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the target variable from [0, 1] to [Y, N]\n",
    "train_processed['subscribe'] = as.factor(ifelse(train_processed['subscribe'] == 1, 'Y', 'N'))\n",
    "test_processed['subscribe'] = as.factor(ifelse(test_processed['subscribe'] == 1, 'Y', 'N'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Tune] Started tuning learner classif.llm for parameter set:\n",
      "                      Type len Def                     Constr Req Tunable Trafo\n",
      "threshold_pruning discrete   -   - 0.01,0.1,0.15,0.2,0.25,0.3   -    TRUE     -\n",
      "nbr_obs_leaf      discrete   -   -   52,131,262,525,1312,2625   -    TRUE     -\n",
      "With control class: TuneControlGrid\n",
      "Imputation value: -0\n",
      "[Tune-x] 1: threshold_pruning=0.01; nbr_obs_leaf=52\n",
      "[Tune-y] 1: auc.test.mean=0.7802661; time: 0.3 min\n",
      "[Tune-x] 2: threshold_pruning=0.1; nbr_obs_leaf=52\n",
      "[Tune-y] 2: auc.test.mean=0.7790630; time: 0.3 min\n",
      "[Tune-x] 3: threshold_pruning=0.15; nbr_obs_leaf=52\n",
      "[Tune-y] 3: auc.test.mean=0.7783884; time: 0.3 min\n",
      "[Tune-x] 4: threshold_pruning=0.2; nbr_obs_leaf=52\n",
      "[Tune-y] 4: auc.test.mean=0.7740686; time: 0.3 min\n",
      "[Tune-x] 5: threshold_pruning=0.25; nbr_obs_leaf=52\n",
      "[Tune-y] 5: auc.test.mean=0.7706940; time: 0.3 min\n",
      "[Tune-x] 6: threshold_pruning=0.3; nbr_obs_leaf=52\n",
      "[Tune-y] 6: auc.test.mean=0.7662159; time: 0.3 min\n",
      "[Tune-x] 7: threshold_pruning=0.01; nbr_obs_leaf=131\n",
      "[Tune-y] 7: auc.test.mean=0.7801765; time: 0.3 min\n",
      "[Tune-x] 8: threshold_pruning=0.1; nbr_obs_leaf=131\n",
      "[Tune-y] 8: auc.test.mean=0.7801765; time: 0.3 min\n",
      "[Tune-x] 9: threshold_pruning=0.15; nbr_obs_leaf=131\n",
      "[Tune-y] 9: auc.test.mean=0.7801765; time: 0.3 min\n",
      "[Tune-x] 10: threshold_pruning=0.2; nbr_obs_leaf=131\n",
      "[Tune-y] 10: auc.test.mean=0.7801765; time: 0.3 min\n",
      "[Tune-x] 11: threshold_pruning=0.25; nbr_obs_leaf=131\n",
      "[Tune-y] 11: auc.test.mean=0.7801765; time: 0.3 min\n",
      "[Tune-x] 12: threshold_pruning=0.3; nbr_obs_leaf=131\n",
      "[Tune-y] 12: auc.test.mean=0.7801765; time: 0.3 min\n",
      "[Tune-x] 13: threshold_pruning=0.01; nbr_obs_leaf=262\n",
      "[Tune-y] 13: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 14: threshold_pruning=0.1; nbr_obs_leaf=262\n",
      "[Tune-y] 14: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 15: threshold_pruning=0.15; nbr_obs_leaf=262\n",
      "[Tune-y] 15: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 16: threshold_pruning=0.2; nbr_obs_leaf=262\n",
      "[Tune-y] 16: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 17: threshold_pruning=0.25; nbr_obs_leaf=262\n",
      "[Tune-y] 17: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 18: threshold_pruning=0.3; nbr_obs_leaf=262\n",
      "[Tune-y] 18: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 19: threshold_pruning=0.01; nbr_obs_leaf=525\n",
      "[Tune-y] 19: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 20: threshold_pruning=0.1; nbr_obs_leaf=525\n",
      "[Tune-y] 20: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 21: threshold_pruning=0.15; nbr_obs_leaf=525\n",
      "[Tune-y] 21: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 22: threshold_pruning=0.2; nbr_obs_leaf=525\n",
      "[Tune-y] 22: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 23: threshold_pruning=0.25; nbr_obs_leaf=525\n",
      "[Tune-y] 23: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 24: threshold_pruning=0.3; nbr_obs_leaf=525\n",
      "[Tune-y] 24: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 25: threshold_pruning=0.01; nbr_obs_leaf=1312\n",
      "[Tune-y] 25: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 26: threshold_pruning=0.1; nbr_obs_leaf=1312\n",
      "[Tune-y] 26: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 27: threshold_pruning=0.15; nbr_obs_leaf=1312\n",
      "[Tune-y] 27: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 28: threshold_pruning=0.2; nbr_obs_leaf=1312\n",
      "[Tune-y] 28: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 29: threshold_pruning=0.25; nbr_obs_leaf=1312\n",
      "[Tune-y] 29: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 30: threshold_pruning=0.3; nbr_obs_leaf=1312\n",
      "[Tune-y] 30: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 31: threshold_pruning=0.01; nbr_obs_leaf=2625\n",
      "[Tune-y] 31: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 32: threshold_pruning=0.1; nbr_obs_leaf=2625\n",
      "[Tune-y] 32: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 33: threshold_pruning=0.15; nbr_obs_leaf=2625\n",
      "[Tune-y] 33: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 34: threshold_pruning=0.2; nbr_obs_leaf=2625\n",
      "[Tune-y] 34: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 35: threshold_pruning=0.25; nbr_obs_leaf=2625\n",
      "[Tune-y] 35: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune-x] 36: threshold_pruning=0.3; nbr_obs_leaf=2625\n",
      "[Tune-y] 36: auc.test.mean=0.7820794; time: 0.3 min\n",
      "[Tune] Result: threshold_pruning=0.15; nbr_obs_leaf=525 : auc.test.mean=0.7820794\n"
     ]
    }
   ],
   "source": [
    "# Set up cross-validation\n",
    "rdesc = makeResampleDesc(\"CV\", iters=10)\n",
    "\n",
    "# Define the model\n",
    "learner <- makeLearner(\"classif.llm\", predict.type=\"prob\", fix.factors.prediction=T)\n",
    "\n",
    "# Define the task\n",
    "train_task <- makeClassifTask(id=\"bank_train\", data=train_processed[, -1], target=\"subscribe\")\n",
    "\n",
    "# Set hyper parameter tuning\n",
    "tune_params <- makeParamSet(\n",
    "  makeDiscreteParam(\"threshold_pruning\", values=c(0.01, 0.10, 0.15, 0.20, 0.25, 0.30)),\n",
    "  makeDiscreteParam(\"nbr_obs_leaf\", values=round(nrow(train_processed) * c(0.01, 0.025, 0.05, 0.1, 0.25, 0.5)))\n",
    ")\n",
    "ctrl = makeTuneControlGrid()\n",
    "\n",
    "# Run the hyper parameter tuning with k-fold CV\n",
    "if (length(tune_params$pars) > 0) {\n",
    "    # Run parameter tuning\n",
    "    res <- tuneParams(learner, task=train_task, resampling=rdesc,\n",
    "      par.set=tune_params, control=ctrl, measures=list(mlr::auc))\n",
    "    \n",
    "    # Extract best model\n",
    "    best_learner <- res$learner\n",
    "    \n",
    "} else {\n",
    "    # Simple cross-validation\n",
    "    res <- resample(learner, train_task, rdesc, measures=list(mlr::auc))\n",
    "    \n",
    "    # No parameter for tuning, only 1 best learner\n",
    "    best_learner <- learner\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with tbe best hyper-parameters\n",
    "best_md <- mlr::train(best_learner, train_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>auc:</strong> 0.801432990341519"
      ],
      "text/latex": [
       "\\textbf{auc:} 0.801432990341519"
      ],
      "text/markdown": [
       "**auc:** 0.801432990341519"
      ],
      "text/plain": [
       "     auc \n",
       "0.801433 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on test data\n",
    "pred <- predict(best_md, newdata=test_processed[, -1])\n",
    "performance(pred, measures=mlr::auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction: 3000 observations\n",
       "predict.type: prob\n",
       "threshold: N=0.50,Y=0.50\n",
       "time: 0.00\n",
       "      prob.Y    prob.N response\n",
       "1 0.10183594 0.8981641        N\n",
       "2 0.04835625 0.9516438        N\n",
       "3 0.13714634 0.8628537        N\n",
       "4 0.02275134 0.9772487        N\n",
       "5 0.04436840 0.9556316        N\n",
       "6 0.05463644 0.9453636        N\n",
       "... (#rows: 3000, #cols: 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on test data\n",
    "pred <- predict(best_md, newdata=test_holdout_processed[, -1])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in data.frame(client_id = test_holdout_processed$client_id, subscribe = pred$data$prob.1): arguments imply differing number of rows: 3000, 0\n",
     "output_type": "error",
     "traceback": [
      "Error in data.frame(client_id = test_holdout_processed$client_id, subscribe = pred$data$prob.1): arguments imply differing number of rows: 3000, 0\nTraceback:\n",
      "1. data.frame(client_id = test_holdout_processed$client_id, subscribe = pred$data$prob.1)",
      "2. stop(gettextf(\"arguments imply differing number of rows: %s\", \n .     paste(unique(nrows), collapse = \", \")), domain = NA)"
     ]
    }
   ],
   "source": [
    "# Output predicted file\n",
    "output <- data.frame(client_id=test_data$client_id, subscribe=pred$data$prob.1)\n",
    "write.csv(output, 'llm.csv', row.names=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Tune] Started tuning learner classif.naiveBayes for parameter set:\n",
      "            Type len Def Constr Req Tunable Trafo\n",
      "laplace discrete   -   - 0,5,by   -    TRUE     -\n",
      "With control class: TuneControlGrid\n",
      "Imputation value: -0\n",
      "[Tune-x] 1: laplace=0\n",
      "[Tune-y] 1: auc.test.mean=0.7685295; time: 0.0 min\n",
      "[Tune-x] 2: laplace=5\n",
      "[Tune-y] 2: auc.test.mean=0.7685295; time: 0.0 min\n",
      "[Tune-x] 3: laplace=by\n",
      "[Tune-y] 3: auc.test.mean=0.7685295; time: 0.0 min\n",
      "[Tune] Result: laplace=5 : auc.test.mean=0.7685295\n"
     ]
    }
   ],
   "source": [
    "# Set up cross-validation\n",
    "rdesc = makeResampleDesc(\"CV\", iters=10)\n",
    "\n",
    "# Define the model\n",
    "learner <- makeLearner(\"classif.naiveBayes\", predict.type=\"prob\", fix.factors.prediction=T)\n",
    "\n",
    "# Define the task\n",
    "train_task <- makeClassifTask(id=\"bank_train\", data=train_processed[, -1], target=\"subscribe\")\n",
    "\n",
    "# Set hyper parameter tuning\n",
    "tune_params <- makeParamSet(\n",
    "    makeDiscreteParam(\"laplace\", values=c(0, 5, by = 0.5))\n",
    ")\n",
    "ctrl = makeTuneControlGrid()\n",
    "\n",
    "# Run the hyper parameter tuning with k-fold CV\n",
    "if (length(tune_params$pars) > 0) {\n",
    "    # Run parameter tuning\n",
    "    res <- tuneParams(learner, task=train_task, resampling=rdesc,\n",
    "      par.set=tune_params, control=ctrl, measures=list(mlr::auc))\n",
    "    \n",
    "    # Extract best model\n",
    "    best_learner <- res$learner\n",
    "    \n",
    "} else {\n",
    "    # Simple cross-validation\n",
    "    res <- resample(learner, train_task, rdesc, measures=list(mlr::auc))\n",
    "    \n",
    "    # No parameter for tuning, only 1 best learner\n",
    "    best_learner <- learner\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with tbe best hyper-parameters\n",
    "best_md <- mlr::train(best_learner, train_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>auc:</strong> 0.774506178962968"
      ],
      "text/latex": [
       "\\textbf{auc:} 0.774506178962968"
      ],
      "text/markdown": [
       "**auc:** 0.774506178962968"
      ],
      "text/plain": [
       "      auc \n",
       "0.7745062 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on test data\n",
    "pred <- predict(best_md, newdata=test_processed[, -1])\n",
    "performance(pred, measures=mlr::auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction: 3000 observations\n",
       "predict.type: prob\n",
       "threshold: N=0.50,Y=0.50\n",
       "time: 0.71\n",
       "     prob.N       prob.Y response\n",
       "1 0.9980282 1.971822e-03        N\n",
       "2 0.9997267 2.732705e-04        N\n",
       "3 0.9775675 2.243252e-02        N\n",
       "4 0.9999950 4.998387e-06        N\n",
       "5 0.9999906 9.412314e-06        N\n",
       "6 0.9997048 2.952445e-04        N\n",
       "... (#rows: 3000, #cols: 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on test data\n",
    "pred <- predict(best_md, newdata=test_holdout_processed[, -1])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in data.frame(client_id = test_data$client_id, subscribe = pred$data$prob.1): arguments imply differing number of rows: 3000, 0\n",
     "output_type": "error",
     "traceback": [
      "Error in data.frame(client_id = test_data$client_id, subscribe = pred$data$prob.1): arguments imply differing number of rows: 3000, 0\nTraceback:\n",
      "1. data.frame(client_id = test_data$client_id, subscribe = pred$data$prob.1)",
      "2. stop(gettextf(\"arguments imply differing number of rows: %s\", \n .     paste(unique(nrows), collapse = \", \")), domain = NA)"
     ]
    }
   ],
   "source": [
    "# Output predicted file\n",
    "output <- data.frame(client_id=test_data$client_id, subscribe=pred$data$prob.1)\n",
    "write.csv(output, 'naiveBayes.csv', row.names=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
